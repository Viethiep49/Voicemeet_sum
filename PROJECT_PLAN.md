# PROJECT PLAN: Smart Meeting Assistant

## ğŸ¯ Má»¥c tiÃªu dá»± Ã¡n

XÃ¢y dá»±ng **Trá»£ lÃ½ há»p thÃ´ng minh** cho doanh nghiá»‡p Viá»‡t Nam, tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i audio cuá»™c há»p thÃ nh biÃªn báº£n chuáº©n doanh nghiá»‡p.

**Cuá»™c thi:** Há»™i thi "TÃŒM KIáº¾M TÃ€I NÄ‚NG CNTT 2025" - Báº£ng D: AI & Blockchain  
**Deadline:** ÄÄƒng kÃ½ 26/12/2025, BÃ¡n káº¿t 28-31/12/2025

---

## ğŸ“‹ YÃªu cáº§u chÃ­nh

### Æ¯u tiÃªn cao (MUST HAVE)
- [ ] Transcription chÃ­nh xÃ¡c cao cho tiáº¿ng Viá»‡t
- [ ] Tá»‘c Ä‘á»™ xá»­ lÃ½ vá»«a Ä‘á»§ (khÃ´ng quÃ¡ cháº­m)
- [ ] Export DOCX theo format biÃªn báº£n doanh nghiá»‡p VN
- [ ] Metadata placeholders Ä‘á»ƒ thÆ° kÃ½ Ä‘iá»n sau

### Æ¯u tiÃªn tháº¥p (NICE TO HAVE)
- [ ] Speaker diarization (phÃ¢n biá»‡t ngÆ°á»i nÃ³i)
- [ ] Chatbot Q&A vá»›i ná»™i dung cuá»™c há»p
- [ ] Export PDF
- [ ] Blockchain verification (demo level)

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PROCESSING PIPELINE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  [Audio File]                                                â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚  â”‚  FFmpeg     â”‚  Preprocess (normalize, resample 16kHz)    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚  Whisper    â”‚  â”‚  Pyannote   â”‚  [Optional: Diarization]  â”‚
â”‚  â”‚  (medium)   â”‚  â”‚  (speaker)  â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                 â”‚                                    â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚     Raw Transcript              â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                â”‚                                             â”‚
â”‚                â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚     Text Preprocessing          â”‚                        â”‚
â”‚  â”‚     â€¢ Clean text                â”‚                        â”‚
â”‚  â”‚     â€¢ Chunk if > 20k chars      â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                â”‚                                             â”‚
â”‚                â–¼ (if chunked)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚     Qwen 2.5 7B                 â”‚                        â”‚
â”‚  â”‚     Summarize each chunk        â”‚                        â”‚
â”‚  â”‚     â†’ Combine summaries         â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                â”‚                                             â”‚
â”‚                â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚     Qwen 2.5 7B                 â”‚                        â”‚
â”‚  â”‚     EXTRACT to JSON             â”‚                        â”‚
â”‚  â”‚     (Structured extraction)     â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                â”‚                                             â”‚
â”‚                â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚     JSON Validation             â”‚                        â”‚
â”‚  â”‚     â€¢ Parse check               â”‚                        â”‚
â”‚  â”‚     â€¢ Schema validation         â”‚                        â”‚
â”‚  â”‚     â€¢ Retry if failed (max 2)   â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                â”‚                                             â”‚
â”‚                â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚     Python Formatter            â”‚                        â”‚
â”‚  â”‚     Apply DOCX template         â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                â”‚                                             â”‚
â”‚                â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚     DOCX Export                 â”‚                        â”‚
â”‚  â”‚     â€¢ AI-generated content      â”‚                        â”‚
â”‚  â”‚     â€¢ Placeholder metadata      â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                â”‚                                             â”‚
â”‚                â–¼                                             â”‚
â”‚         [Final DOCX File]                                    â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

### Core Processing
| Component | Technology | Purpose |
|-----------|------------|---------|
| Audio Preprocessing | FFmpeg | Normalize, resample to 16kHz mono |
| Speech-to-Text | Faster-Whisper (medium) | Transcription tiáº¿ng Viá»‡t |
| Speaker Diarization | Pyannote-audio | PhÃ¢n biá»‡t ngÆ°á»i nÃ³i [Optional] |
| Summarization | Qwen 2.5 7B via Ollama | Extract + Summarize |
| Export | python-docx | Táº¡o file DOCX |

### Backend
| Component | Technology | Purpose |
|-----------|------------|---------|
| API Server | FastAPI | HTTP endpoints |
| Task Queue | In-memory dict | Job management (Ä‘á»§ cho demo) |
| File Storage | Local filesystem | Output files |

### Frontend
| Component | Technology | Purpose |
|-----------|------------|---------|
| UI | HTML/CSS/JS (vanilla) | Single page app |
| Styling | Custom CSS | Modern gradient UI |

**LÆ°u Ã½:** KhÃ´ng cáº§n database cho demo. In-memory storage Ä‘á»§ dÃ¹ng.

---

## ğŸ“Š JSON Extraction Schema

LLM sáº½ extract transcript thÃ nh JSON format sau:

```json
{
  "meeting_info": {
    "main_purpose": "string - Má»¥c Ä‘Ã­ch chÃ­nh cuá»™c há»p",
    "topics_discussed": ["string - CÃ¡c chá»§ Ä‘á» Ä‘Æ°á»£c bÃ n"],
    "participants_mentioned": ["string - TÃªn ngÆ°á»i Ä‘Æ°á»£c nháº¯c Ä‘áº¿n trong audio"]
  },
  "discussions": [
    {
      "topic": "string - Chá»§ Ä‘á»",
      "points": [
        {
          "speaker": "string hoáº·c null - Ai nÃ³i (náº¿u biáº¿t)",
          "content": "string - Ná»™i dung Ã½ kiáº¿n",
          "type": "opinion | proposal | question | answer | decision"
        }
      ],
      "conclusion": "string hoáº·c null - Káº¿t luáº­n cho topic nÃ y"
    }
  ],
  "decisions": [
    {
      "content": "string - Ná»™i dung quyáº¿t Ä‘á»‹nh",
      "made_by": "string hoáº·c null - Ai quyáº¿t Ä‘á»‹nh"
    }
  ],
  "action_items": [
    {
      "task": "string - CÃ´ng viá»‡c cáº§n lÃ m",
      "assignee": "string hoáº·c null - NgÆ°á»i phá»¥ trÃ¡ch",
      "deadline": "string hoáº·c null - Háº¡n hoÃ n thÃ nh",
      "priority": "high | medium | low | null"
    }
  ],
  "other_notes": "string hoáº·c null - Ghi chÃº khÃ¡c"
}
```

---

## ğŸ“ DOCX Template - BiÃªn báº£n há»p doanh nghiá»‡p VN

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚              CÃ”NG TY [_______________________]              â”‚
â”‚                     (Placeholder - thÆ° kÃ½ Ä‘iá»n)             â”‚
â”‚                                                             â”‚
â”‚                     BIÃŠN Báº¢N Há»ŒP                           â”‚
â”‚              Sá»‘: _____/BB-__________                        â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Thá»i gian: NgÃ y ___/___/______, tá»« ___:___ Ä‘áº¿n ___:___   â”‚
â”‚  Äá»‹a Ä‘iá»ƒm: [________________________________________________]â”‚
â”‚  HÃ¬nh thá»©c: â˜ Trá»±c tiáº¿p    â˜ Trá»±c tuyáº¿n    â˜ Káº¿t há»£p      â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  THÃ€NH PHáº¦N THAM Dá»°:                                       â”‚
â”‚                                                             â”‚
â”‚  Chá»§ trÃ¬:  [______________________] - [______________]     â”‚
â”‚  ThÆ° kÃ½:   [______________________] - [______________]     â”‚
â”‚                                                             â”‚
â”‚  ThÃ nh viÃªn:                                               â”‚
â”‚  1. [______________________] - [______________]            â”‚
â”‚  2. [______________________] - [______________]            â”‚
â”‚  3. [______________________] - [______________]            â”‚
â”‚                                                             â”‚
â”‚  Váº¯ng máº·t: [______________________________________________]â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  I. Má»¤C ÄÃCH CUá»˜C Há»ŒP                                      â”‚
â”‚     [AI generated: meeting_info.main_purpose]              â”‚
â”‚                                                             â”‚
â”‚  II. Ná»˜I DUNG THáº¢O LUáº¬N                                    â”‚
â”‚                                                             â”‚
â”‚     1. [discussions[0].topic]                              â”‚
â”‚        â€¢ [speaker]: [content]                              â”‚
â”‚        â€¢ [speaker]: [content]                              â”‚
â”‚        â†’ Káº¿t luáº­n: [conclusion]                            â”‚
â”‚                                                             â”‚
â”‚     2. [discussions[1].topic]                              â”‚
â”‚        ...                                                 â”‚
â”‚                                                             â”‚
â”‚  III. CÃC QUYáº¾T Äá»ŠNH                                       â”‚
â”‚     1. [decisions[0].content]                              â”‚
â”‚     2. [decisions[1].content]                              â”‚
â”‚                                                             â”‚
â”‚  IV. PHÃ‚N CÃ”NG CÃ”NG VIá»†C                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STT â”‚ Ná»™i dung         â”‚ Phá»¥ trÃ¡ch     â”‚ Deadline   â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  1  â”‚ [task]           â”‚ [assignee]    â”‚ [deadline] â”‚   â”‚
â”‚  â”‚  2  â”‚ [task]           â”‚ [assignee]    â”‚ [deadline] â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  V. Ã KIáº¾N KHÃC                                            â”‚
â”‚     [AI generated: other_notes]                            â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Cuá»™c há»p káº¿t thÃºc vÃ o lÃºc ___:___, cÃ¹ng ngÃ y.            â”‚
â”‚                                                             â”‚
â”‚         THÆ¯ KÃ                         CHá»¦ TRÃŒ             â”‚
â”‚     (KÃ½, ghi rÃµ há» tÃªn)           (KÃ½, ghi rÃµ há» tÃªn)      â”‚
â”‚                                                             â”‚
â”‚  ____________________           ____________________        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**NguyÃªn táº¯c:**
- Sections I, II, III, IV, V: AI generate tá»« JSON extraction
- Metadata (cÃ´ng ty, thá»i gian, thÃ nh pháº§n...): Placeholder Ä‘á»ƒ thÆ° kÃ½ Ä‘iá»n sau
- Font: Times New Roman 13pt (chuáº©n vÄƒn báº£n VN)

---

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c Ä‘á» xuáº¥t

```
smart_meeting_assistant/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ backend.py              # FastAPI server (giá»¯ nguyÃªn structure)
â”‚   â””â”€â”€ static/
â”‚       â””â”€â”€ index.html          # Frontend UI
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py             # App configuration
â”‚   â””â”€â”€ prompts.py              # [NEW] Prompt templates cho LLM
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ meeting_pipeline.py # Main orchestrator
â”‚   â”‚
â”‚   â”œâ”€â”€ transcription/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ audio_processor.py  # FFmpeg preprocessing
â”‚   â”‚   â”œâ”€â”€ whisper_service.py  # Speech-to-text
â”‚   â”‚   â””â”€â”€ diarization.py      # [NEW][Optional] Speaker ID
â”‚   â”‚
â”‚   â”œâ”€â”€ summarization/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ qwen_service.py     # [REFACTOR] LLM interaction
â”‚   â”‚   â”œâ”€â”€ extractor.py        # [NEW] JSON extraction logic
â”‚   â”‚   â””â”€â”€ chunker.py          # [NEW] Text chunking logic
â”‚   â”‚
â”‚   â”œâ”€â”€ export/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ docx_exporter.py    # [NEW] DOCX generation
â”‚   â”‚   â””â”€â”€ templates/          # [NEW] DOCX templates
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â”œâ”€â”€ file_handler.py
â”‚       â”œâ”€â”€ system_checker.py
â”‚       â””â”€â”€ text_processor.py
â”‚
â”œâ”€â”€ output/                     # Generated files
â”œâ”€â”€ models/                     # Cached models
â”œâ”€â”€ logs/                       # Log files
â”œâ”€â”€ temp/                       # Temporary files
â”‚
â”œâ”€â”€ DEPLOYMENT/
â”‚   â”œâ”€â”€ setup.bat
â”‚   â”œâ”€â”€ run_fastapi.bat
â”‚   â””â”€â”€ check_system.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements_fastapi.txt
â”œâ”€â”€ PROJECT_PLAN.md             # This file
â””â”€â”€ README.md
```

---

## ğŸ”§ Implementation Tasks

### Phase 1: Refactor Summarization (Priority: HIGH)

#### Task 1.1: Táº¡o config/prompts.py
```python
# config/prompts.py

CHUNK_SUMMARIZE_PROMPT = """
TÃ³m táº¯t ngáº¯n gá»n Ä‘oáº¡n cuá»™c há»p sau báº±ng tiáº¿ng Viá»‡t.
Giá»¯ láº¡i cÃ¡c thÃ´ng tin quan trá»ng: ai nÃ³i gÃ¬, quyáº¿t Ä‘á»‹nh gÃ¬, viá»‡c gÃ¬ cáº§n lÃ m.
KhÃ´ng thÃªm thÃ´ng tin khÃ´ng cÃ³ trong transcript.

TRANSCRIPT:
---
{transcript}
---

TÃ“M Táº®T:
"""

EXTRACTION_PROMPT = """
Báº¡n lÃ  trá»£ lÃ½ phÃ¢n tÃ­ch cuá»™c há»p doanh nghiá»‡p Viá»‡t Nam.

NHIá»†M Vá»¤: PhÃ¢n tÃ­ch transcript vÃ  trÃ­ch xuáº¥t thÃ´ng tin theo JSON schema.

QUY Táº®C Báº®T BUá»˜C:
1. CHá»ˆ tráº£ vá» JSON, khÃ´ng cÃ³ text nÃ o khÃ¡c
2. KHÃ”NG bá»‹a thÃ´ng tin khÃ´ng cÃ³ trong transcript
3. Náº¿u khÃ´ng cháº¯c cháº¯n, Ä‘á»ƒ null
4. Giá»¯ nguyÃªn tÃªn riÃªng tiáº¿ng Viá»‡t
5. TÃ³m táº¯t ngáº¯n gá»n, sÃºc tÃ­ch

JSON SCHEMA:
```json
{schema}
```

TRANSCRIPT:
---
{transcript}
---

JSON OUTPUT:
"""

EXTRACTION_SCHEMA = {
    "meeting_info": {
        "main_purpose": "string - Má»¥c Ä‘Ã­ch chÃ­nh cuá»™c há»p",
        "topics_discussed": ["string"],
        "participants_mentioned": ["string"]
    },
    "discussions": [
        {
            "topic": "string",
            "points": [
                {
                    "speaker": "string or null",
                    "content": "string",
                    "type": "opinion | proposal | question | answer | decision"
                }
            ],
            "conclusion": "string or null"
        }
    ],
    "decisions": [
        {
            "content": "string",
            "made_by": "string or null"
        }
    ],
    "action_items": [
        {
            "task": "string",
            "assignee": "string or null",
            "deadline": "string or null",
            "priority": "high | medium | low | null"
        }
    ],
    "other_notes": "string or null"
}
```

#### Task 1.2: Táº¡o src/summarization/chunker.py
```python
# src/summarization/chunker.py

from typing import List
from ..utils.logger import logger

class TextChunker:
    """Handle text chunking for long transcripts"""
    
    def __init__(self, max_chunk_size: int = 15000, overlap: int = 500):
        self.max_chunk_size = max_chunk_size
        self.overlap = overlap
    
    def should_chunk(self, text: str) -> bool:
        """Check if text needs chunking (threshold: 20k chars)"""
        return len(text) > 20000
    
    def chunk(self, text: str) -> List[str]:
        """
        Split text into overlapping chunks at sentence boundaries
        
        Args:
            text: Full transcript text
            
        Returns:
            List of text chunks
        """
        if not self.should_chunk(text):
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + self.max_chunk_size
            
            if end >= len(text):
                chunks.append(text[start:])
                break
            
            # Find sentence boundary (., !, ?)
            sentence_end = max(
                text.rfind('.', start, end),
                text.rfind('!', start, end),
                text.rfind('?', start, end)
            )
            
            if sentence_end > start + self.max_chunk_size // 2:
                end = sentence_end + 1
            
            chunks.append(text[start:end].strip())
            start = end - self.overlap
        
        logger.info(f"Split transcript into {len(chunks)} chunks")
        return chunks
    
    def combine_summaries(self, summaries: List[str]) -> str:
        """
        Combine chunk summaries into single text
        
        Args:
            summaries: List of summarized chunks
            
        Returns:
            Combined summary text
        """
        return "\n\n".join(summaries)
```

#### Task 1.3: Táº¡o src/summarization/extractor.py
```python
# src/summarization/extractor.py

import json
import re
from typing import Optional, Callable
from ..utils.logger import logger
from config.prompts import EXTRACTION_PROMPT, EXTRACTION_SCHEMA

class MeetingExtractor:
    """Extract structured data from transcript using LLM"""
    
    def __init__(self, qwen_service):
        self.qwen = qwen_service
        self.schema = EXTRACTION_SCHEMA
    
    def extract(
        self, 
        transcript: str, 
        max_retries: int = 2,
        progress_callback: Optional[Callable] = None
    ) -> dict:
        """
        Extract meeting info to structured JSON
        
        Args:
            transcript: Meeting transcript text
            max_retries: Number of retry attempts
            progress_callback: Progress update callback
            
        Returns:
            Validated JSON dict or fallback structure
        """
        for attempt in range(max_retries):
            try:
                if progress_callback:
                    progress_callback(85 + attempt * 3, f"Extracting info (attempt {attempt + 1})...")
                
                # Build prompt
                prompt = EXTRACTION_PROMPT.format(
                    schema=json.dumps(self.schema, indent=2, ensure_ascii=False),
                    transcript=transcript
                )
                
                # Call LLM
                response = self.qwen.extract_json(prompt)
                
                # Validate JSON
                data = self._validate_json(response)
                if data:
                    logger.info("JSON extraction successful")
                    return data
                    
            except Exception as e:
                logger.warning(f"Extraction attempt {attempt + 1} failed: {e}")
        
        # Fallback
        logger.warning("Using fallback extraction")
        return self._fallback_extraction(transcript)
    
    def _validate_json(self, response: str) -> Optional[dict]:
        """
        Parse and validate JSON response
        
        Args:
            response: Raw LLM response
            
        Returns:
            Parsed dict or None if invalid
        """
        try:
            # Clean response - remove markdown code blocks if present
            cleaned = response.strip()
            cleaned = re.sub(r'^```json\s*', '', cleaned)
            cleaned = re.sub(r'^```\s*', '', cleaned)
            cleaned = re.sub(r'\s*```$', '', cleaned)
            
            data = json.loads(cleaned)
            
            # Basic schema validation
            required_keys = ['meeting_info', 'discussions', 'decisions', 'action_items']
            if all(key in data for key in required_keys):
                return data
            
            logger.warning(f"Missing required keys in JSON response")
            return None
            
        except json.JSONDecodeError as e:
            logger.warning(f"JSON parse error: {e}")
            return None
    
    def _fallback_extraction(self, transcript: str) -> dict:
        """
        Basic extraction when LLM fails
        
        Args:
            transcript: Original transcript
            
        Returns:
            Minimal valid structure
        """
        return {
            "meeting_info": {
                "main_purpose": "Cuá»™c há»p Ä‘Æ°á»£c ghi nháº­n tá»« audio",
                "topics_discussed": [],
                "participants_mentioned": []
            },
            "discussions": [
                {
                    "topic": "Ná»™i dung cuá»™c há»p",
                    "points": [
                        {
                            "speaker": None,
                            "content": transcript[:2000] + "..." if len(transcript) > 2000 else transcript,
                            "type": "opinion"
                        }
                    ],
                    "conclusion": None
                }
            ],
            "decisions": [],
            "action_items": [],
            "other_notes": "LÆ°u Ã½: Extraction tá»± Ä‘á»™ng khÃ´ng thÃ nh cÃ´ng. Vui lÃ²ng xem transcript Ä‘áº§y Ä‘á»§."
        }
```

#### Task 1.4: Refactor src/summarization/qwen_service.py
```python
# src/summarization/qwen_service.py

import requests
import json
from typing import Optional, Callable
from ..utils.logger import logger
from config.settings import SUMMARIZATION
from config.prompts import CHUNK_SUMMARIZE_PROMPT

class QwenService:
    """Qwen LLM service via Ollama"""
    
    def __init__(self, config=None):
        self.config = config or SUMMARIZATION
        self.base_url = self.config.base_url
    
    def summarize_chunk(self, chunk: str) -> str:
        """
        Summarize a single chunk of transcript
        
        Args:
            chunk: Text chunk to summarize
            
        Returns:
            Summarized text
        """
        prompt = CHUNK_SUMMARIZE_PROMPT.format(transcript=chunk)
        return self._call_ollama(prompt)
    
    def extract_json(self, prompt: str) -> str:
        """
        Extract structured JSON from text using custom prompt
        
        Args:
            prompt: Full prompt with schema and transcript
            
        Returns:
            Raw LLM response (should be JSON)
        """
        return self._call_ollama(prompt, temperature=0.1)  # Lower temperature for structured output
    
    def _call_ollama(self, prompt: str, temperature: Optional[float] = None) -> str:
        """
        Low-level Ollama API call
        
        Args:
            prompt: Input prompt
            temperature: Override temperature (optional)
            
        Returns:
            Model response text
        """
        url = f"{self.base_url}/api/generate"
        
        temp = temperature if temperature is not None else self.config.temperature
        
        payload = {
            "model": self.config.model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": temp,
                "num_predict": self.config.max_tokens
            }
        }
        
        try:
            response = requests.post(url, json=payload, timeout=300)
            response.raise_for_status()
            result = response.json()
            return result.get("response", "").strip()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Ollama API error: {e}")
            raise RuntimeError(f"Ollama API error: {e}")
    
    def check_connection(self) -> bool:
        """Check if Ollama is running"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=2)
            return response.status_code == 200
        except:
            return False
```

### Phase 2: DOCX Export (Priority: HIGH)

#### Task 2.1: Táº¡o src/export/__init__.py
```python
# src/export/__init__.py
"""Export modules"""
```

#### Task 2.2: Táº¡o src/export/docx_exporter.py
```python
# src/export/docx_exporter.py

from pathlib import Path
from docx import Document
from docx.shared import Pt, Cm, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.table import WD_TABLE_ALIGNMENT
from docx.oxml.ns import qn
from docx.oxml import OxmlElement

from ..utils.logger import logger

class MeetingDocxExporter:
    """Export meeting data to DOCX format"""
    
    def __init__(self):
        self.doc = None
    
    def export(self, extracted_data: dict, output_path: str) -> str:
        """
        Generate DOCX from extracted JSON data
        
        Args:
            extracted_data: JSON tá»« MeetingExtractor
            output_path: ÄÆ°á»ng dáº«n file output
            
        Returns:
            Path to generated file
        """
        self.doc = Document()
        self._setup_styles()
        
        # Build document
        self._add_header()
        self._add_metadata_placeholders()
        self._add_separator()
        self._add_purpose_section(extracted_data)
        self._add_discussion_section(extracted_data)
        self._add_decisions_section(extracted_data)
        self._add_action_items_table(extracted_data)
        self._add_other_notes(extracted_data)
        self._add_separator()
        self._add_signature_section()
        
        # Save
        self.doc.save(output_path)
        logger.info(f"DOCX exported: {output_path}")
        return output_path
    
    def _setup_styles(self):
        """Setup Times New Roman 13pt default"""
        style = self.doc.styles['Normal']
        style.font.name = 'Times New Roman'
        style.font.size = Pt(13)
        
        # Set font for East Asian text
        style._element.rPr.rFonts.set(qn('w:eastAsia'), 'Times New Roman')
    
    def _add_header(self):
        """Add company name placeholder + title"""
        # Company name
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = p.add_run("CÃ”NG TY [_______________________]")
        run.bold = True
        run.font.size = Pt(14)
        
        # Title
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = p.add_run("BIÃŠN Báº¢N Há»ŒP")
        run.bold = True
        run.font.size = Pt(16)
        
        # Document number
        p = self.doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        p.add_run("Sá»‘: _____/BB-__________")
        
        self.doc.add_paragraph()
    
    def _add_metadata_placeholders(self):
        """Add time, location, participants placeholders"""
        # Thá»i gian
        p = self.doc.add_paragraph()
        run = p.add_run("Thá»i gian: ")
        run.bold = True
        p.add_run("NgÃ y ___/___/______, tá»« ___:___ Ä‘áº¿n ___:___")
        
        # Äá»‹a Ä‘iá»ƒm
        p = self.doc.add_paragraph()
        run = p.add_run("Äá»‹a Ä‘iá»ƒm: ")
        run.bold = True
        p.add_run("[__________________________________________________]")
        
        # HÃ¬nh thá»©c
        p = self.doc.add_paragraph()
        run = p.add_run("HÃ¬nh thá»©c: ")
        run.bold = True
        p.add_run("â˜ Trá»±c tiáº¿p    â˜ Trá»±c tuyáº¿n    â˜ Káº¿t há»£p")
        
        self.doc.add_paragraph()
        
        # ThÃ nh pháº§n tham dá»±
        p = self.doc.add_paragraph()
        run = p.add_run("THÃ€NH PHáº¦N THAM Dá»°:")
        run.bold = True
        
        # Chá»§ trÃ¬
        p = self.doc.add_paragraph()
        run = p.add_run("Chá»§ trÃ¬: ")
        run.bold = True
        p.add_run("[______________________] - [_______________]")
        
        # ThÆ° kÃ½
        p = self.doc.add_paragraph()
        run = p.add_run("ThÆ° kÃ½: ")
        run.bold = True
        p.add_run("[______________________] - [_______________]")
        
        # ThÃ nh viÃªn
        p = self.doc.add_paragraph()
        run = p.add_run("ThÃ nh viÃªn:")
        run.bold = True
        
        for i in range(1, 6):
            p = self.doc.add_paragraph()
            p.add_run(f"   {i}. [______________________] - [_______________]")
        
        # Váº¯ng máº·t
        p = self.doc.add_paragraph()
        run = p.add_run("Váº¯ng máº·t: ")
        run.bold = True
        p.add_run("[__________________________________________________]")
    
    def _add_separator(self):
        """Add horizontal line separator"""
        p = self.doc.add_paragraph()
        p.add_run("â”€" * 70)
    
    def _add_purpose_section(self, data: dict):
        """Section I: Má»¥c Ä‘Ã­ch cuá»™c há»p"""
        p = self.doc.add_paragraph()
        run = p.add_run("I. Má»¤C ÄÃCH CUá»˜C Há»ŒP")
        run.bold = True
        
        meeting_info = data.get("meeting_info", {})
        purpose = meeting_info.get("main_purpose", "")
        
        p = self.doc.add_paragraph()
        if purpose:
            p.add_run(f"   {purpose}")
        else:
            p.add_run("   [Ná»™i dung Ä‘Æ°á»£c AI tÃ³m táº¯t tá»« cuá»™c há»p]")
        
        self.doc.add_paragraph()
    
    def _add_discussion_section(self, data: dict):
        """Section II: Ná»™i dung tháº£o luáº­n"""
        p = self.doc.add_paragraph()
        run = p.add_run("II. Ná»˜I DUNG THáº¢O LUáº¬N")
        run.bold = True
        
        discussions = data.get("discussions", [])
        
        if discussions:
            for i, disc in enumerate(discussions, 1):
                # Topic header
                p = self.doc.add_paragraph()
                run = p.add_run(f"   {i}. {disc.get('topic', 'Chá»§ Ä‘á»')}")
                run.bold = True
                
                # Discussion points
                for point in disc.get("points", []):
                    speaker = point.get("speaker", "")
                    content = point.get("content", "")
                    
                    p = self.doc.add_paragraph()
                    if speaker:
                        run = p.add_run(f"      â€¢ {speaker}: ")
                        run.italic = True
                        p.add_run(content)
                    else:
                        p.add_run(f"      â€¢ {content}")
                
                # Conclusion
                conclusion = disc.get("conclusion")
                if conclusion:
                    p = self.doc.add_paragraph()
                    run = p.add_run("      â†’ Káº¿t luáº­n: ")
                    run.bold = True
                    p.add_run(conclusion)
        else:
            p = self.doc.add_paragraph()
            p.add_run("   [KhÃ´ng cÃ³ ná»™i dung tháº£o luáº­n Ä‘Æ°á»£c ghi nháº­n]")
        
        self.doc.add_paragraph()
    
    def _add_decisions_section(self, data: dict):
        """Section III: CÃ¡c quyáº¿t Ä‘á»‹nh"""
        p = self.doc.add_paragraph()
        run = p.add_run("III. CÃC QUYáº¾T Äá»ŠNH")
        run.bold = True
        
        decisions = data.get("decisions", [])
        
        if decisions:
            for i, dec in enumerate(decisions, 1):
                p = self.doc.add_paragraph()
                p.add_run(f"   {i}. {dec.get('content', '')}")
        else:
            p = self.doc.add_paragraph()
            p.add_run("   [KhÃ´ng cÃ³ quyáº¿t Ä‘á»‹nh Ä‘Æ°á»£c Ä‘Æ°a ra]")
        
        self.doc.add_paragraph()
    
    def _add_action_items_table(self, data: dict):
        """Section IV: Báº£ng phÃ¢n cÃ´ng cÃ´ng viá»‡c"""
        p = self.doc.add_paragraph()
        run = p.add_run("IV. PHÃ‚N CÃ”NG CÃ”NG VIá»†C")
        run.bold = True
        
        self.doc.add_paragraph()
        
        # Create table
        table = self.doc.add_table(rows=1, cols=4)
        table.style = 'Table Grid'
        
        # Header row
        header_cells = table.rows[0].cells
        headers = ["STT", "Ná»™i dung cÃ´ng viá»‡c", "NgÆ°á»i phá»¥ trÃ¡ch", "Deadline"]
        for i, header in enumerate(headers):
            header_cells[i].text = header
            for paragraph in header_cells[i].paragraphs:
                for run in paragraph.runs:
                    run.bold = True
        
        # Data rows
        action_items = data.get("action_items", [])
        
        if action_items:
            for i, item in enumerate(action_items, 1):
                row = table.add_row().cells
                row[0].text = str(i)
                row[1].text = item.get("task", "")
                row[2].text = item.get("assignee") or "[___________]"
                row[3].text = item.get("deadline") or "[___/___]"
        else:
            # Empty rows for manual fill
            for i in range(1, 4):
                row = table.add_row().cells
                row[0].text = str(i)
                row[1].text = ""
                row[2].text = "[___________]"
                row[3].text = "[___/___]"
        
        self.doc.add_paragraph()
    
    def _add_other_notes(self, data: dict):
        """Section V: Ã kiáº¿n khÃ¡c"""
        p = self.doc.add_paragraph()
        run = p.add_run("V. Ã KIáº¾N KHÃC")
        run.bold = True
        
        notes = data.get("other_notes", "")
        
        p = self.doc.add_paragraph()
        if notes:
            p.add_run(f"   {notes}")
        else:
            p.add_run("   [KhÃ´ng cÃ³]")
        
        self.doc.add_paragraph()
    
    def _add_signature_section(self):
        """Footer with signature placeholders"""
        p = self.doc.add_paragraph()
        p.add_run("Cuá»™c há»p káº¿t thÃºc vÃ o lÃºc ___:___, cÃ¹ng ngÃ y.")
        
        self.doc.add_paragraph()
        self.doc.add_paragraph()
        
        # Signature table
        table = self.doc.add_table(rows=4, cols=2)
        
        # Row 1: Titles
        table.cell(0, 0).text = "THÆ¯ KÃ"
        table.cell(0, 0).paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
        for run in table.cell(0, 0).paragraphs[0].runs:
            run.bold = True
        
        table.cell(0, 1).text = "CHá»¦ TRÃŒ"
        table.cell(0, 1).paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
        for run in table.cell(0, 1).paragraphs[0].runs:
            run.bold = True
        
        # Row 2: Instructions
        table.cell(1, 0).text = "(KÃ½, ghi rÃµ há» tÃªn)"
        table.cell(1, 0).paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        table.cell(1, 1).text = "(KÃ½, ghi rÃµ há» tÃªn)"
        table.cell(1, 1).paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # Row 3: Empty space
        table.cell(2, 0).text = ""
        table.cell(2, 1).text = ""
        
        # Row 4: Signature line
        table.cell(3, 0).text = "_______________________"
        table.cell(3, 0).paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        table.cell(3, 1).text = "_______________________"
        table.cell(3, 1).paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
```

### Phase 3: Update Pipeline (Priority: HIGH)

#### Task 3.1: Update src/pipeline/meeting_pipeline.py
```python
# ThÃªm imports vÃ  update class MeetingPipeline

# ThÃªm vÃ o Ä‘áº§u file:
from ..summarization.chunker import TextChunker
from ..summarization.extractor import MeetingExtractor
from ..export.docx_exporter import MeetingDocxExporter

# Update __init__:
def __init__(self):
    self.audio_processor = AudioProcessor()
    self.whisper_service = WhisperService()
    self.qwen_service = QwenService()
    self.chunker = TextChunker()
    self.extractor = MeetingExtractor(self.qwen_service)
    self.docx_exporter = MeetingDocxExporter()

# Update process method Ä‘á»ƒ return thÃªm docx_path
# ThÃªm logic chunking vÃ  extraction
# Gá»i docx_exporter.export() á»Ÿ cuá»‘i
```

### Phase 4: Update Backend & Frontend (Priority: MEDIUM)

#### Task 4.1: Update app/backend.py
- ThÃªm `docx` vÃ o job result
- Update download endpoint Ä‘á»ƒ support docx
- Äáº£m báº£o CORS cho file download

#### Task 4.2: Update app/static/index.html
- ThÃªm button "Táº£i BiÃªn báº£n (DOCX)"
- Style cho button má»›i

---

## ğŸ“¦ Dependencies cáº§n thÃªm

```txt
# ThÃªm vÃ o requirements_fastapi.txt

# DOCX Export
python-docx>=0.8.11
```

CÃ i Ä‘áº·t:
```bash
pip install python-docx --break-system-packages
```

---

## ğŸ§ª Testing Checklist

### Unit Tests
- [ ] TextChunker.chunk() vá»›i text dÃ i
- [ ] TextChunker.should_chunk() threshold
- [ ] MeetingExtractor.extract() vá»›i transcript tháº­t
- [ ] MeetingExtractor._validate_json() vá»›i invalid JSON
- [ ] MeetingExtractor._fallback_extraction()
- [ ] MeetingDocxExporter.export() output valid DOCX
- [ ] QwenService.summarize_chunk()
- [ ] QwenService.extract_json()

### Integration Tests
- [ ] Full pipeline vá»›i file audio 5 phÃºt
- [ ] Full pipeline vá»›i file audio 30 phÃºt
- [ ] Full pipeline vá»›i file audio 1-2 giá»
- [ ] DOCX má»Ÿ Ä‘Æ°á»£c trong MS Word
- [ ] DOCX má»Ÿ Ä‘Æ°á»£c trong Google Docs
- [ ] DOCX cÃ³ Ä‘Ãºng format tiáº¿ng Viá»‡t

### Demo Checklist
- [ ] Upload file hoáº¡t Ä‘á»™ng
- [ ] Progress bar cáº­p nháº­t real-time
- [ ] Download transcript TXT
- [ ] Download DOCX biÃªn báº£n
- [ ] DOCX cÃ³ Ä‘á»§ 5 sections
- [ ] DOCX cÃ³ placeholders Ä‘á»ƒ Ä‘iá»n
- [ ] Font Times New Roman 13pt

---

## â±ï¸ Timeline Æ°á»›c tÃ­nh

| Phase | Tasks | Thá»i gian |
|-------|-------|-----------|
| Phase 1 | Refactor Summarization | 2-3 giá» |
| Phase 2 | DOCX Export | 2-3 giá» |
| Phase 3 | Update Pipeline | 1-2 giá» |
| Phase 4 | Update Backend/Frontend | 1 giá» |
| Testing | Full testing | 2 giá» |
| **Total** | | **8-11 giá»** |

---

## ğŸš€ Execution Order cho Claude Code CLI

```bash
# Thá»© tá»± thá»±c hiá»‡n:

1. Äá»c vÃ  hiá»ƒu codebase hiá»‡n táº¡i
   - Xem src/summarization/qwen_service.py
   - Xem src/pipeline/meeting_pipeline.py
   - Xem app/backend.py

2. Táº¡o config/prompts.py
   - CHUNK_SUMMARIZE_PROMPT
   - EXTRACTION_PROMPT
   - EXTRACTION_SCHEMA

3. Táº¡o src/summarization/chunker.py
   - Class TextChunker

4. Táº¡o src/summarization/extractor.py
   - Class MeetingExtractor

5. Refactor src/summarization/qwen_service.py
   - ThÃªm summarize_chunk()
   - ThÃªm extract_json()
   - Giá»¯ backward compatible

6. Táº¡o src/export/__init__.py

7. Táº¡o src/export/docx_exporter.py
   - Class MeetingDocxExporter

8. Update src/pipeline/meeting_pipeline.py
   - Import new modules
   - Add chunking logic
   - Add extraction logic
   - Add DOCX export

9. Update app/backend.py
   - Add docx to job result
   - Update download endpoint

10. Update app/static/index.html
    - Add DOCX download button

11. Test end-to-end vá»›i file audio tháº­t

12. Fix bugs náº¿u cÃ³

13. DONE - Sáºµn sÃ ng demo!
```

---

## ğŸ“ LÆ°u Ã½ quan trá»ng cho Claude Code CLI

1. **KHÃ”NG Sá»¬A** cÃ¡c file Ä‘ang hoáº¡t Ä‘á»™ng tá»‘t:
   - `src/transcription/whisper_service.py` âœ“
   - `src/transcription/audio_processor.py` âœ“
   - `src/utils/*` âœ“

2. **REFACTOR cáº©n tháº­n**:
   - `src/summarization/qwen_service.py` - thÃªm methods má»›i, giá»¯ methods cÅ©
   - `src/pipeline/meeting_pipeline.py` - thÃªm logic má»›i

3. **Táº O Má»šI**:
   - `config/prompts.py`
   - `src/summarization/chunker.py`
   - `src/summarization/extractor.py`
   - `src/export/__init__.py`
   - `src/export/docx_exporter.py`

4. **Test sau má»—i phase** Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng break existing functionality

5. **Output files** lÆ°u vÃ o `output/` folder

6. **Error handling** Ä‘áº§y Ä‘á»§ vá»›i logging

7. **Tiáº¿ng Viá»‡t** - táº¥t cáº£ messages vÃ  output pháº£i há»— trá»£ Unicode

---

## âœ… Success Criteria

Demo thÃ nh cÃ´ng khi:

1. âœ… Upload file M4A/MP4 â†’ Xá»­ lÃ½ khÃ´ng lá»—i
2. âœ… Progress bar hiá»ƒn thá»‹ Ä‘Ãºng tiáº¿n trÃ¬nh
3. âœ… Transcript tiáº¿ng Viá»‡t chÃ­nh xÃ¡c >90%
4. âœ… JSON extraction cÃ³ Ä‘á»§ fields
5. âœ… DOCX cÃ³ Ä‘á»§ 5 sections theo template
6. âœ… DOCX cÃ³ placeholders cho metadata
7. âœ… DOCX dÃ¹ng font Times New Roman 13pt
8. âœ… Tá»•ng thá»i gian xá»­ lÃ½ file 1 giá» < 15 phÃºt
9. âœ… GiÃ¡m kháº£o áº¥n tÆ°á»£ng vá»›i output quality

---

## ğŸ¯ Äiá»ƒm khÃ¡c biá»‡t Ä‘á»ƒ nháº¥n máº¡nh khi demo

1. **Vietnamese-first AI** - Tá»‘i Æ°u cho tiáº¿ng Viá»‡t doanh nghiá»‡p
2. **Privacy-first** - Cháº¡y hoÃ n toÃ n local, khÃ´ng upload cloud
3. **Enterprise-grade output** - BiÃªn báº£n chuáº©n phÃ¡p lÃ½ VN
4. **Practical** - ThÆ° kÃ½ chá»‰ cáº§n Ä‘iá»n metadata, ná»™i dung AI lo
