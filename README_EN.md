# ğŸ¤ Voicemeet_sum

Automated meeting transcription and summarization application for Zoom recordings.

## ğŸ¯ Features

- âœ… **Transcription**: Audio to text with [Faster-Whisper](https://github.com/guillaumekln/faster-whisper) (medium model)
- âœ… **Summarization**: Auto-summary with [Qwen 2.5 7B](https://ollama.ai/library/qwen2.5:7b)
- âœ… **FFmpeg**: Audio preprocessing (normalize, resample, remove silence)
- âœ… **GUI**: Web interface with Gradio
- âœ… **Progress Tracking**: Real-time progress updates
- âœ… **Multilingual**: Supports Vietnamese + Japanese

## ğŸ¯ System Requirements

```yaml
OS: Windows 10/11 (64-bit)
CPU: Intel i5 or better
RAM: 16GB or more
GPU: NVIDIA RTX 4070 (recommended, 12GB VRAM)
Storage: 20GB free space
Internet: Required for initial model download
```

## ğŸš€ Installation

### Method 1: Automated Setup (Recommended)

1. **Clone repository**
   ```bash
   git clone https://github.com/your-username/voicemeet_sum.git
   cd voicemeet_sum
   ```

2. **Run setup script**
   ```bash
   DEPLOYMENT\setup.bat
   ```

3. **Install Ollama and Qwen**
   ```bash
   # Install Ollama
   DEPLOYMENT\install_ollama.bat
   
   # Download Qwen model
   ollama pull qwen2.5:7b
   ```

4. **Run app**
   ```bash
   DEPLOYMENT\run_app.bat
   ```

### Method 2: Manual Setup

1. **Install dependencies**
   ```bash
   python -m venv venv
   venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Install FFmpeg**
   - Download from https://ffmpeg.org/
   - Add to PATH

3. **Install Ollama**
   - Download from https://ollama.ai/
   - Run: `ollama pull qwen2.5:7b`

4. **Run app**
   ```bash
   python app\gui.py
   ```

## ğŸ“– Usage

1. **Start app**
   ```bash
   DEPLOYMENT\run_app.bat
   ```

2. **Upload audio file**
   - Drag & drop Zoom recording (M4A, MP4, MP3)
   - Or click upload button

3. **Process**
   - Click "ğŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½"
   - Wait 10-15 minutes (for 2-hour file)

4. **Download results**
   - `transcript_*.txt`: Full content
   - `summary_*.txt`: Summary

## âš™ï¸ Configuration

Edit `config/settings.py`:

```python
# Whisper config
TRANSCRIPTION.model = "medium"          # medium, large-v2, large-v3
TRANSCRIPTION.compute_type = "float16"  # float16, float32, int8
TRANSCRIPTION.language = "vi"           # vi, ja, en

# Qwen config
SUMMARIZATION.model = "qwen2.5:7b"      # qwen2.5:7b, qwen2.5:14b
SUMMARIZATION.temperature = 0.3         # 0.0 - 1.0
```

## ğŸ“Š Performance

### Processing Time (2-hour audio)

```
FFmpeg preprocessing:     30-60 sec
Whisper transcription:    6-8 min
Qwen summarization:       2-3 min
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                    9-12 min
Speed:                    10-13x realtime
```

### Resource Usage

```
VRAM: 5-6 GB (Whisper medium)
RAM:  10-12 GB total
  - Whisper: 3-4 GB
  - Qwen: 7-8 GB
  - System: 2 GB
```

## ğŸ§ª Testing

```bash
# Run tests
pytest tests/

# Coverage
pytest --cov=src tests/

# Lint
flake8 src/ app/
black --check src/ app/
```

## ğŸ“ Project Structure

```
voicemeet_sum/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ gui.py              # Gradio interface
â”‚   â””â”€â”€ themes.py           # Custom themes
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py         # Configuration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ meeting_pipeline.py    # Main pipeline
â”‚   â”œâ”€â”€ transcription/
â”‚   â”‚   â”œâ”€â”€ whisper_service.py     # Faster-Whisper
â”‚   â”‚   â””â”€â”€ audio_processor.py     # FFmpeg
â”‚   â”œâ”€â”€ summarization/
â”‚   â”‚   â””â”€â”€ qwen_service.py        # Qwen via Ollama
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py
â”‚       â”œâ”€â”€ file_handler.py
â”‚       â”œâ”€â”€ system_checker.py
â”‚       â””â”€â”€ text_processor.py
â”œâ”€â”€ tests/
â”œâ”€â”€ DEPLOYMENT/
â”‚   â”œâ”€â”€ setup.bat           # One-click setup
â”‚   â””â”€â”€ run_app.bat         # Launch app
â””â”€â”€ requirements.txt
```

## ğŸ› Troubleshooting

### FFmpeg not found
```bash
# Install FFmpeg
DEPLOYMENT\install_ffmpeg.bat

# Or download and add to PATH
```

### Ollama not running
```bash
# Start Ollama
ollama serve

# In another terminal
ollama pull qwen2.5:7b
```

### GPU not being used
```bash
# Check CUDA
python -c "import torch; print(torch.cuda.is_available())"

# Install PyTorch with CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Out of Memory
- Reduce model size: `medium` â†’ `small`
- Reduce `chunk_size` in config
- Close other applications

## ğŸ“ License

MIT License - see [LICENSE](LICENSE)

## ğŸ¤ Contributing

Contributions welcome! Please open an issue or PR.

## ğŸ“§ Contact

- Issues: https://github.com/your-username/voicemeet_sum/issues
- Email: your-email@example.com

---

Made with â¤ï¸ for efficient meeting transcription

