# Troubleshooting Guide

## ‚ùì Common Issues and Solutions

### 1. FFmpeg kh√¥ng t√¨m th·∫•y

**L·ªói:**
```
RuntimeError: FFmpeg kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t
```

**Gi·∫£i ph√°p:**
1. C√†i ƒë·∫∑t FFmpeg:
   ```bash
   DEPLOYMENT\install_ffmpeg.bat
   ```

2. Ho·∫∑c th·ªß c√¥ng:
   - Download t·ª´ https://ffmpeg.org/download.html
   - Gi·∫£i n√©n v√† th√™m v√†o PATH
   - Test: `ffmpeg -version`

### 2. Ollama kh√¥ng ch·∫°y

**L·ªói:**
```
RuntimeError: Ollama ch∆∞a ƒë∆∞·ª£c kh·ªüi ƒë·ªông
```

**Gi·∫£i ph√°p:**
1. Kh·ªüi ƒë·ªông Ollama:
   ```bash
   ollama serve
   ```

2. Trong terminal kh√°c, pull model:
   ```bash
   ollama pull qwen2.5:7b
   ```

3. Test:
   ```bash
   curl http://localhost:11434/api/tags
   ```

### 3. GPU kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng

**L·ªói:**
```
Whisper using CPU instead of CUDA
```

**Gi·∫£i ph√°p:**
1. Ki·ªÉm tra CUDA:
   ```bash
   python -c "import torch; print(torch.cuda.is_available())"
   ```

2. C√†i PyTorch v·ªõi CUDA:
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```

3. Ki·ªÉm tra GPU:
   ```bash
   nvidia-smi
   ```

### 4. Out of Memory

**L·ªói:**
```
CUDA out of memory
```

**Gi·∫£i ph√°p:**
1. Gi·∫£m model size:
   - Edit `config/settings.py`
   - Change: `TRANSCRIPTION.model = "small"`

2. Gi·∫£m batch size:
   - Change: `TRANSCRIPTION.compute_type = "int8"`

3. ƒê√≥ng c√°c ·ª©ng d·ª•ng kh√°c

4. Restart v√† th·ª≠ l·∫°i

### 5. Audio file kh√¥ng h·ª£p l·ªá

**L·ªói:**
```
File audio kh√¥ng h·ª£p l·ªá
```

**Gi·∫£i ph√°p:**
1. Ki·ªÉm tra format: M4A, MP4, MP3, WAV, FLAC
2. Ki·ªÉm tra file kh√¥ng corrupt
3. Chuy·ªÉn ƒë·ªïi format n·∫øu c·∫ßn:
   ```bash
   ffmpeg -i input.m4a output.wav
   ```

### 6. Processing ch·∫≠m

**V·∫•n ƒë·ªÅ:**
```
Processing m·∫•t qu√° nhi·ªÅu th·ªùi gian
```

**Gi·∫£i ph√°p:**
1. S·ª≠ d·ª•ng GPU
2. Gi·∫£m model size
3. T·∫Øt c√°c options kh√¥ng c·∫ßn:
   - Normalize: False
   - Remove silence: False

### 7. Model kh√¥ng download

**L·ªói:**
```
Failed to download model
```

**Gi·∫£i ph√°p:**
1. Ki·ªÉm tra k·∫øt n·ªëi internet
2. Th·ª≠ download th·ªß c√¥ng:
   ```bash
   python DEPLOYMENT\download_models.py
   ```

3. Ho·∫∑c download t·ª´ HuggingFace

### 8. Port 7860 ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng

**L·ªói:**
```
Port 7860 is already in use
```

**Gi·∫£i ph√°p:**
1. ƒê·ªïi port trong `app/gui.py`:
   ```python
   app.launch(server_port=7861)
   ```

2. Ho·∫∑c ƒë√≥ng app ƒëang ch·∫°y

### 9. Vietnamese text b·ªã l·ªói encoding

**V·∫•n ƒë·ªÅ:**
```
Vietnamese characters corrupted
```

**Gi·∫£i ph√°p:**
1. ƒê·∫£m b·∫£o UTF-8 encoding
2. Ki·ªÉm tra terminal encoding:
   ```bash
   chcp 65001
   ```

### 10. Ollama model kh√¥ng t√¨m th·∫•y

**L·ªói:**
```
Model qwen2.5:7b not found
```

**Gi·∫£i ph√°p:**
1. List models:
   ```bash
   ollama list
   ```

2. Pull model:
   ```bash
   ollama pull qwen2.5:7b
   ```

3. Test:
   ```bash
   ollama run qwen2.5:7b "Hello"
   ```

## üîß System Requirements Check

Ch·∫°y script ƒë·ªÉ ki·ªÉm tra h·ªá th·ªëng:

```bash
python DEPLOYMENT\check_system.py
```

Script s·∫Ω ki·ªÉm tra:
- ‚úÖ Python version
- ‚úÖ FFmpeg
- ‚úÖ GPU/CUDA
- ‚úÖ Ollama

## üìû Getting Help

N·∫øu v·∫´n g·∫∑p v·∫•n ƒë·ªÅ:

1. Ki·ªÉm tra logs trong `logs/` folder
2. Ch·∫°y v·ªõi debug mode:
   ```python
   import logging
   logging.basicConfig(level=logging.DEBUG)
   ```

3. M·ªü issue tr√™n GitHub v·ªõi:
   - Error message
   - System specs
   - Log file

## üîç Debug Mode

ƒê·ªÉ b·∫≠t debug logging:

```python
# In config/settings.py or src/utils/logger.py
setup_logger(level=logging.DEBUG)
```

## üìù Log Locations

- Application logs: `logs/YYYYMMDD_HHMMSS.log`
- FFmpeg logs: Console output
- Whisper logs: Console output
- Ollama logs: `~/.ollama/logs/`

